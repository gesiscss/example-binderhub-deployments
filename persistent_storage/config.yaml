# NOTE this image also includes jupyterhub==1.0.0 in requirements.txt
image:
  name: gesiscss/k8s-bhub-example
  tag: queryparams-1

nodeSelector:
  base: worker

config:
  BinderHub:
    base_url: /services/binder/
#    hub_url: https://notebooks-test.gesis.org
    query_parameter_names: ['run-nbgitpuller']

    appendix: |
      USER root
      ENV BINDER_URL={binder_url}
      ENV REPO_URL={repo_url}
      USER $NB_USER
      RUN pip install nbgitpuller
      RUN jupyter serverextension enable --py nbgitpuller --sys-prefix

jupyterhub:
  hub:
    # clone custom JupyterHub templates into a volume
    initContainers:
      - name: git-clone-templates
        image: alpine/git
        args:
          - clone
          - --single-branch
          - --branch=master
          - --depth=1
          - --
          - https://github.com/gesiscss/example-binderhub-deployments.git
          - /etc/jupyterhub/custom
        securityContext:
          runAsUser: 0
        volumeMounts:
          - name: custom-templates
            mountPath: /etc/jupyterhub/custom
    extraVolumes:
      - name: custom-templates
        emptyDir: {}
    extraVolumeMounts:
      - name: custom-templates
        mountPath: /etc/jupyterhub/custom

    # increase to 10 in order to decrease hub restarts
    # because informative errors from spawner also increases failure_count
    consecutiveFailureLimit: 10
#    baseUrl: /

    services:
      binder:
        url: http://194.95.75.9:30193  # base worker
        oauth_redirect_uri: "https://notebooks-test.gesis.org/services/binder/oauth_callback"

    extraConfig:
      hub_slow_spawn_timeout: |
        c.JupyterHub.tornado_settings['slow_spawn_timeout']= 10
      # set pod restart_policy back to default value OnFailure, because user pod sometimes fails when
      # PostStart hook doesn't finish first cloning repo before docker entrypoint (start notebook server)
      neverRestart: |
        c.KubeSpawner.extra_pod_config.update({'restart_policy': 'OnFailure'})
      templates: |
        c.JupyterHub.template_paths = ['/etc/jupyterhub/custom/persistent_storage/jupyterhub/templates']
      binder: |
        from tornado import web
        from kubespawner import KubeSpawner
        from os.path import join

        class BinderSpawner(KubeSpawner):
          banned_images = []
          # allowed_images = []

          def strip_repo_url(self, repo_url):
              return repo_url.lstrip("http://").lstrip("https://").rstrip('.git').rstrip('/')

          def url_to_dir(self, url):
            url = self.strip_repo_url(url)
            return '_'.join(reversed(url.split('/')[-2:]))

          def start(self):
            # clean attributes, so we dont save wrong values in state when error happens
            if hasattr(self, 'repo_url'):
              delattr(self, 'repo_url')
            if hasattr(self, 'ref'):
              delattr(self, 'ref')

            self.reset_delete_list = False
            state = self.get_state()
            # get last saved projects
            projects = state['projects']
            # get list of projects to be deleted from disk just after spawn
            delete_list = state['delete_list']

            # get image spec from user_options
            if 'image' in self.user_options and \
              'repo_url' in self.user_options and \
              'token' in self.user_options:
              # check if user has reached to projects limit
              # NOTE this must be checked before self.repo_url and self.ref are set!
              repo_url = self.user_options['repo_url'].rstrip('.git').rstrip('/')
              projects_limit = 5
              projects_repo_list = [self.strip_repo_url(p[0]) for p in projects]
              if self.strip_repo_url(repo_url) not in projects_repo_list and len(projects) >= projects_limit:
                self.log.error("No more than %s projects is allowed. One must be deleted before a new project can be created.", projects_limit)
                raise web.HTTPError(409, "No more than %s projects is allowed. One must be deleted before a new project can be created.", projects_limit)

              # binder service sets the image spec via user options
              self.image = self.user_options['image']
              # NOTE: user can pass any options through API (without using binder) too
              if self.image in self.banned_images or self.image.split(':')[0] in self.banned_images:
                self.log.error("Image %s is in banned.", self.image)
                raise web.HTTPError(409, "Image %s is in banned.", self.image)
              self.repo_url = repo_url
              self.ref = self.image.split(':')[-1]
            else:
              # user starts server without binder form (default)
              # for example via spawn url or by refresing user page when server was stopped
              # launch last repo in projects
              self.repo_url, self.ref, _ = projects[-1]

            # prepare postStart command
            delete_cmd = f"rm -rf {' '.join(['~/'+self.url_to_dir(d) for d in delete_list])}" if delete_list else ""
            shared_folder = '~/shared_storage'  # shared folder between projects of user
            repo_dir = '~/'+self.url_to_dir(self.repo_url)
            if repo_dir == shared_folder:
              repo_dir += '_'
            symlink_dir = join(repo_dir, shared_folder[2:])
            # symlink_cmd: create a symlink to {shared_folder} if directory or symlink with same name does not exist
            symlink_cmd = f"if [ -d {symlink_dir} ]; " \
                          f"then echo 'directory {symlink_dir} exists'; " \
                          f"elif [ -L {symlink_dir} ]; " \
                          f"then echo '{symlink_dir} is a symlink'; " \
                          f"else mkdir -p {shared_folder} && ln -s {shared_folder} {symlink_dir}; fi"
            gitpuller_cmd = f"gitpuller {self.repo_url} master {repo_dir}"
            # NOTE: PostStart -> This hook executes immediately after a container is created.
            # However, there is no guarantee that the hook will execute before the container ENTRYPOINT.
            # thats why sometimes we get error from SingleUserNotebookApp when launching a repo for the first time:
            # "No such notebook dir: '/home/jovyan/{repo_dir}'",
            if self.user_options.get('run-nbgitpuller', 'true').lower() in ['true', '1']:
              commands = [delete_cmd, gitpuller_cmd, symlink_cmd] if delete_cmd else [gitpuller_cmd, symlink_cmd]
              command = " && ".join(commands)
            else:
              # NOTE: dont mkdir -p repo_dir, because nbgitpuller fails with empty dir (non-git dir)
              command = delete_cmd
            self.lifecycle_hooks = {'postStart': {'exec': {'command': ["/bin/sh", "-c", command]}}} if command else {}
            self.notebook_dir = repo_dir

            self.reset_delete_list = True
            return super().start()

          def get_state_field(self, name):
            # just get current value of a field in state
            # dont update thing in state
            self.update_projects = False
            reset_delete_list = getattr(self, 'reset_delete_list', False)
            self.reset_delete_list = False
            state = self.get_state()
            self.update_projects = True
            self.reset_delete_list = reset_delete_list
            return state[name]

          def get_state(self):
            _state = self.orm_spawner.state
            # default_projects is only to use when first login
            default_projects = [['https://github.com/gesiscss/data_science_image', 'master', 'never']]
            projects = _state.get('projects', []) if _state else default_projects
            delete_list = _state.get('delete_list', []) if _state else []

            state = super().get_state()
            state['projects'] = projects
            state['delete_list'] = delete_list

            if getattr(self, 'update_projects', True) is True and hasattr(self, 'repo_url') and hasattr(self, 'ref'):
              # project is started or already running or is stopped,
              # so move project to the end and update the last launched time (last seen)
              from datetime import datetime
              e = [self.repo_url, self.ref, datetime.utcnow().isoformat() + 'Z']
              _projects = []
              for p in projects:
                if p[0] != e[0]:
                  _projects.append(p)
              _projects.append(e)
              state['projects'] = _projects

            if getattr(self, 'reset_delete_list', False) is True:
              state['delete_list'] = []

            return state
        c.JupyterHub.spawner_class = BinderSpawner
      extra_handlers: |
        import json
        from tornado.escape import json_decode
        from jupyterhub.handlers import BaseHandler
        class ProjectDeletionHandler(BaseHandler):

            def strip_repo_url(self, repo_url):
                return repo_url.lstrip("http://").lstrip("https://").rstrip('.git').rstrip('/')

            @web.authenticated
            def post(self):
                # https://github.com/zhanglongqi/TornadoAJAXSample
                response_to_send = {}
                user = self.current_user
                if user.running:
                    response_to_send["error"] = "Project deletion is not allowed while user server is running."
                else:
                    json_obj = json_decode(self.request.body)
                    if "repo_url" in json_obj and "name" in json_obj and "id" in json_obj:
                        repo_url = self.strip_repo_url(json_obj["repo_url"])
                        delete_on_disk = json_obj.get("delete_on_disk", False)
                        state = user.spawner.get_state()
                        projects = []
                        delete_list = []
                        found = False
                        for project in state.get("projects", []):
                            if repo_url != self.strip_repo_url(project[0]):
                                projects.append(project)
                            else:
                              found = True
                              if delete_on_disk is True and repo_url not in delete_list:
                                  delete_list.append(repo_url)
                        if found is True:
                            state["projects"] = projects
                            state["delete_list"].extend(delete_list)
                            user.spawner.orm_spawner.state = state
                            self.db.commit()

                            response_to_send["success"] = f"Project {json_obj['name']} is deleted."
                            response_to_send["id"] = json_obj["id"]
                        else:
                            response_to_send["error"] = f"Project {json_obj['name']} ({json_obj['repo_url']}) doesn't exist."
                    else:
                        response_to_send["error"] = "Bad request."
                self.write(json.dumps(response_to_send))

        c.JupyterHub.extra_handlers = [(r'/delete_project', ProjectDeletionHandler),]
#  auth:
#    github:
#      callbackUrl: "https://notebooks-test.gesis.org/hub/oauth_callback"

  singleuser:
    storage:
      type: dynamic
      capacity: 5Gi
    image:
      # https://github.com/gesiscss/data_science_image
      name: gesiscss/singleuser-orc
      tag: "r2d-09c7bce"
